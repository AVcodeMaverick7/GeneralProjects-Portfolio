{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROUP 7\n",
    "\n",
    "\n",
    "## ADM_HOMEWORK 4_Part 2\n",
    "\n",
    "####   *  JOANNA BRONIAREK\n",
    "####   *  MATTEO CAVALLETTI\n",
    "####   *  VIKRANTH ALE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Finding the duplicates !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries to perform hashing of the passwords\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  To perform the Hashing of Passwords, we have adopted the following Division method to calculate the Hashvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division method for creating hash function\n",
    "We implemented hash function according to:\n",
    "$$ h(k) = k\\mod{m} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Creating a default dictionary to store as values the numbers, that are linked to each hash value\n",
    "+ Then, while loading the **passwords2.txt** file we are adding elements to the \"hash_dic\" dictionary.\n",
    "+ We chose 1000000000007 as **m** because we need a table size that can accommodate these large values. It is because the passwords in the Input data are great in number.\n",
    "+ using builtin function **ord** to get the ascii value for each string and converting into its equivalent integer raised to order 8 to get a large range of hash values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A) Hashing the Passwords : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a default dictionary to store hash values for each password in the given file\n",
    "\n",
    "hash_dic = defaultdict(list)\n",
    "\n",
    "with open(\"E:\\SAPIENZA\\HOMEWORKS\\ADM\\HW4\\passwords2.txt\") as f:\n",
    "    for row in f:\n",
    "        r= row.replace('\\n','')\n",
    "        c = sum([ord(i)**8 for i in list(r)])\n",
    "        h = c % 1000000000007\n",
    "        hash_dic[h].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pickle to save hash_dic into a file\n",
    "# Unable to upload pickle files as they are very large and also due to size limitations of 100 mb on GitHub\n",
    "\n",
    "with open('hash_dic.pickle', 'wb') as file:\n",
    "    pickle.dump(hash_dic, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Pickle File\n"
     ]
    }
   ],
   "source": [
    "# Loading file from Pickle\n",
    "print('Loading from Pickle File')\n",
    "pickle_output = open(\"hash_dic.pickle\",\"rb\")\n",
    "hash_dic = pickle.load(pickle_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the count of False Positives, Duplicates and Storing them to a dictionary \n",
    "\n",
    "false_positives = 0\n",
    "duplicates = 0\n",
    "interesting_dict={}\n",
    "\n",
    "for k, v in hash_dic.items():\n",
    "    if len(v)>1:\n",
    "        if len(set(v))==len(v):\n",
    "            false_positives += len(v)-1\n",
    "            # only unique values --> collisions\n",
    "        else: \n",
    "            duplicates += len(v) - len(set(v))\n",
    "            false_positives += len(set(v)) - 1\n",
    "            interesting_dict[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5028\n",
      "10000000\n"
     ]
    }
   ],
   "source": [
    "# Printing the Total number of False Positives and Duplicate when the position of string is not considered\n",
    "\n",
    "print('false_positives')\n",
    "print('duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to collect all the duplicates into a list with the help of a temporary dictionary for iterations\n",
    "\n",
    "def find_duplicates(values):\n",
    "    duplicates = []\n",
    "    tmp_dict = {}\n",
    "    for v in values:\n",
    "        try: tmp_dict[v] += 1\n",
    "        except: tmp_dict[v] = 1\n",
    "    for kk, vv in tmp_dict.items(): \n",
    "        if vv>1: duplicates.append(kk)\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving duplicates to a List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatess = []\n",
    "\n",
    "for k,v in interesting_dict.items():\n",
    "    duplicatess.extend(find_duplicates(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy to save the duplicates into a csv file\n",
    "\n",
    "np.savetxt(\"duplicates_part1.csv\",duplicatess,delimiter=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Hashing the Passwords : With Respective To Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another default dictionary to generate hash value with respective to the position of the given input string\n",
    "\n",
    "hash_dic2 = defaultdict(list)\n",
    "with open(\"E:\\SAPIENZA\\HOMEWORKS\\ADM\\HW4\\passwords2.txt\")as f:\n",
    "    for row in f:\n",
    "        r= row.replace('\\n','')\n",
    "        c = sum([(ord(r[i])**7)*(i+1) for i in range(0,20)])\n",
    "        h = c % 1000000000007\n",
    "        hash_dic2[h].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the dictionary to pickle file\n"
     ]
    }
   ],
   "source": [
    "# Saving the Hashvalues to pickle file \n",
    "# Unable to upload pickle files as they are very large and also due to size limitations of 100 mb on GitHub\n",
    "print('Saving the dictionary to pickle file')\n",
    "with open('hash_dic2.pickle', 'wb') as file:\n",
    "    pickle.dump(hash_dic2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Pickle File\n"
     ]
    }
   ],
   "source": [
    "# Loading file from Pickle\n",
    "print('Loading from Pickle File')\n",
    "#pickle_output = open(\"hash_dic2.pickle\",\"rb\")\n",
    "#hash_dic = pickle.load(pickle_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the count of False Positives, Duplicates and Storing them to a dictionary \n",
    "\n",
    "false_positives = 0\n",
    "duplicates = 0\n",
    "interesting_dict={}\n",
    "\n",
    "for k, v in hash_dic2.items():\n",
    "    if len(v)>1:\n",
    "        if len(set(v))==len(v):\n",
    "            false_pasitives += len(v)-1\n",
    "            # only unique values --> collisions\n",
    "        else: \n",
    "            duplicates += len(v) - len(set(v))\n",
    "            false_positives += len(set(v)) - 1\n",
    "            interesting_dict[k]=v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  There is a difference when Hashing the Input string with respective to position as there is tremendous change in the number of duplicates  produced, this is something noteworthy  i.e almost half a million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5550"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of False Positives with respective to position\n",
    "\n",
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(values):\n",
    "    duplicates = []\n",
    "    tmp_dict = {}\n",
    "    for v in values:\n",
    "        try: tmp_dict[v] += 1\n",
    "        except: tmp_dict[v] = 1\n",
    "    for kk, vv in tmp_dict.items(): \n",
    "        if vv>1: duplicates.append(kk)\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Function to create the List of Duplicates with respective to postion of Input string \n",
    "\n",
    "duplicatess2 = []\n",
    "for k, v in interesting_dict.items():\n",
    "    duplicatess2.extend(find_duplicates(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicatess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the duplicates to a csv file using numpy\n",
    "\n",
    "np.savetxt(\"duplicates_part2.csv\", duplicatess2, delimiter=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
